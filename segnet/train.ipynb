{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np \n",
    "from keras import *\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint ,TensorBoard\n",
    "from SegNet0 import *\n",
    "from SegNet import *\n",
    "from FCN32 import *\n",
    "from Models.utils import *\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "from keras import backend as K \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import gdal\n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "# data for training  \n",
    "from keras.applications import vgg16\n",
    " \n",
    "def generateDataTF(batch_size,img_w,img_h,n_label,image_names=[],label_names=[]): \n",
    "    print ('gen-Sub-Image-Data...')\n",
    "    image_filepath ='D:\\Python\\seg-data\\data_MB/'\n",
    "    batch_num=0\n",
    "    while True:   \n",
    "        bs=batch_size\n",
    "        \n",
    "        dataset = gdal.Open(image_filepath+image_names[batch_num%len(image_names)])\n",
    "        im_width = dataset.RasterXSize #栅格矩阵的列数\n",
    "        im_height = dataset.RasterYSize #栅格矩阵的行数\n",
    "        #print(im_width ,im_height)\n",
    "        label_data=cv2.imread(image_filepath+label_names[batch_num%len(image_names)],cv2.IMREAD_GRAYSCALE)\n",
    "        #yield(label_data.shape)\n",
    "        train_data = []  \n",
    "        train_label =  []  \n",
    "        i=0\n",
    "        while (bs-i)!=0:\n",
    "            random_width = random.randint(0, im_width - img_w - 1)\n",
    "            random_height = random.randint(0, im_height - img_h - 1)\n",
    "            tif_roi=dataset.ReadAsArray(random_width,random_height,img_w,img_h)\n",
    "            if (np.sum(tif_roi[0]==0)/(im_width*im_height))<0.5:\n",
    "                data_roi=cv2.merge(tif_roi)  \n",
    "                label_roi = to_categorical((label_data[random_height: random_height + img_h , random_width: random_width + img_w]).flatten(), num_classes=n_label)\n",
    "                train_data.append( data_roi)  \n",
    "                train_label.append(label_roi)\n",
    "                i=i+1\n",
    "                #yield(random_width,img_w,random_height,img_h)\n",
    "                #yield(np.array(data_roi).shape,np.array(label_roi).shape)    \n",
    "        #yield(np.array(train_data).shape,np.array(train_label).shape)    \n",
    "        yield(np.array(train_data),np.array(train_label))\n",
    "        batch_num=batch_num+1\n",
    "#image_names_set=['test.tif']\n",
    "#label_names_set=['test_label.png']\n",
    "#for i in(generateDataTF(8,256,256,2,image_names_set,label_names_set)):\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(key='SegNet',EPOCHS = 10,BatchSize = 4,train_numb_per_epoch = 10*8,valid_rate = 0.2,img_w = 256,img_h = 256): \n",
    "    EPOCHS = EPOCHS\n",
    "    BS = BatchSize\n",
    "    img_w = img_w  \n",
    "    img_h = img_h\n",
    "\n",
    "    train_numb=train_numb_per_epoch*EPOCHS\n",
    "    valid_numb = train_numb*valid_rate\t\n",
    "\n",
    "    method = {\n",
    "    \"FCN32\": FCN32,\n",
    "    #\"fcn8\": FCN8.FCN8,\n",
    "    'SegNet': SegNet,\n",
    "    'SegNet0': SegNet0,\n",
    "    #'unet': UNet.UNet\n",
    "    }\n",
    "    m = method[key]()\n",
    "\n",
    "    m.compile(loss='categorical_crossentropy',optimizer=\"adadelta\",metrics=['acc'])\n",
    "    \n",
    "    modelcheck = ModelCheckpoint('D:\\Python\\seg-data/model/%s_model.h5' % key,#modelcheck = ModelCheckpoint('..\\..\\Python\\seg-data/model/SegNet-'+time.strftime(f'%Y-%m-%d-%a-%H-%M-%S',time.localtime(time.time()))+'.h5',\n",
    "                                 monitor='val_acc',\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')  \n",
    "    tb=TensorBoard(log_dir='D:\\Python\\seg-data/log/%s_log/' % key)\n",
    "    callableTF = [modelcheck,tb]   \n",
    "\n",
    "    print (\"the number of train data is\",train_numb,train_numb//BS)  \n",
    "    print (\"the number of val data is\",valid_numb,valid_numb//BS)\n",
    "    H = m.fit_generator(generator=generateDataTF(BS,img_w,img_h,2,['test.tif'],['test_label.png']),\n",
    "                            steps_per_epoch=train_numb_per_epoch,\n",
    "                            epochs=EPOCHS,\n",
    "                            verbose=0,\n",
    "                            validation_data=generateDataTF(BS,img_w,img_h,2,['test.tif'],['test_label.png']),\n",
    "                            validation_steps=train_numb_per_epoch*valid_rate,\n",
    "                            callbacks=callableTF,\n",
    "                            max_q_size=1)  \n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on %s Satellite Seg\" % key)\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"D:\\Python\\seg-data/model/%s plot.png\"% key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build enceder done..\n",
      "Tensor(\"max_unpooling2d_1/max_unpooling2d_1/Size_1:0\", shape=(), dtype=int32) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Tensor(\"max_unpooling2d_2/max_unpooling2d_2/Size_1:0\", shape=(), dtype=int32) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Tensor(\"max_unpooling2d_3/max_unpooling2d_3/Size_1:0\", shape=(), dtype=int32) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Tensor(\"max_unpooling2d_4/max_unpooling2d_4/Size_1:0\", shape=(), dtype=int32) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Tensor(\"max_unpooling2d_5/max_unpooling2d_5/Size_1:0\", shape=(), dtype=int32) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "WARNING:tensorflow:From c:\\users\\chao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "the number of train data is 8000 1000\n",
      "the number of val data is 1600.0 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., steps_per_epoch=80, epochs=100, verbose=0, validation_data=<generator..., validation_steps=16.0, callbacks=[<keras.ca..., max_queue_size=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen-Sub-Image-Data...gen-Sub-Image-Data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(key='SegNet',EPOCHS = 100,BatchSize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train(key='SegNet',EPOCHS = 100,BatchSize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
