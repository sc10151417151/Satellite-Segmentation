{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization,Reshape,Permute,Activation  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering('th')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import gdal\n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "  \n",
    "#data_shape = 360*480  \n",
    "img_w = 256  \n",
    "img_h = 256  \n",
    "#有一个为背景  \n",
    "n_label =2\n",
    "  \n",
    "classes = [0. ,  1]  \n",
    "  \n",
    "labelencoder = LabelEncoder()  \n",
    "labelencoder.fit(classes)  \n",
    "\n",
    "image_sets = ['1.png','2.png','3.png']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, grayscale=False):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "        img = np.array(img,dtype=\"float\") / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(val_rate = 0.25):\n",
    "    train_url = []    \n",
    "    train_set = []\n",
    "    val_set  = []\n",
    "    filepath ='./data_MB/test/'  \n",
    "    for pic in os.listdir(filepath + 'src'):\n",
    "        train_url.append(pic)\n",
    "    random.shuffle(train_url)\n",
    "    total_num = len(train_url)\n",
    "    val_num = int(val_rate * total_num)\n",
    "    for i in range(len(train_url)):\n",
    "        if i < val_num:\n",
    "            val_set.append(train_url[i]) \n",
    "        else:\n",
    "            train_set.append(train_url[i])\n",
    "    return train_set,val_set\n",
    "# data for training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for training  \n",
    "def generateData(batch_size,data=[]): \n",
    "    print ('generateData...')\n",
    "    filepath ='./data_MB/test/'  \n",
    "    while True:  \n",
    "        train_data = []  \n",
    "        train_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))): \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            img = np.load((filepath + 'src/' + url))\n",
    "            #img = np.load( filepath + 'src/' + url ) \n",
    "            train_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,-1))  \n",
    " \n",
    "            train_label.append(label)  \n",
    "            if batch % batch_size==0: \n",
    "        \n",
    "                train_data = np.array(train_data)  \n",
    "                \n",
    "                train_label = np.array(train_label).flatten()  \n",
    "                train_label = labelencoder.transform(train_label)  \n",
    "                train_label = to_categorical(train_label, num_classes=n_label)  \n",
    "                train_label = train_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (train_data,train_label)  \n",
    "                train_data = []  \n",
    "                train_label = []  \n",
    "                batch = 0  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data for validation \n",
    "def generateValidData(batch_size,data=[]):  \n",
    "    print ('generateValidData...')\n",
    "    filepath ='./data_MB/test/'  \n",
    "    while True:  \n",
    "        valid_data = []  \n",
    "        valid_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))):  \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            img = np.load((filepath + 'src/' + url))\n",
    "            #img = np.load( filepath + 'src/' + url ) \n",
    "            valid_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,-1))  \n",
    " \n",
    "            valid_label.append(label) \n",
    "            if batch % batch_size==0:  \n",
    "                valid_data = np.array(valid_data)  \n",
    "                valid_label = np.array(valid_label).flatten()  \n",
    "                valid_label = labelencoder.transform(valid_label)  \n",
    "                valid_label = to_categorical(valid_label, num_classes=n_label)  \n",
    "                valid_label = valid_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (valid_data,valid_label)  \n",
    "                valid_data = []  \n",
    "                valid_label = []  \n",
    "                batch = 0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def SegNet():  \n",
    "    model = Sequential()  \n",
    "    #encoder  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(4,img_w,img_h),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(8,8)  \n",
    "    #decoder  \n",
    "    model.add(UpSampling2D(size=(2,2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(256,256)  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(4,img_w, img_h), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(n_label, (1, 1), strides=(1, 1), padding='same'))  \n",
    "    model.add(Reshape((n_label,img_w*img_h)))  \n",
    "    #axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)  \n",
    "    model.add(Permute((2,1)))  \n",
    "    model.add(Activation('softmax'))  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  \n",
    "    model.summary()  \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(): \n",
    "    EPOCHS = 1000\n",
    "    BS = 4\n",
    "    model = SegNet() \n",
    "    \n",
    "    modelcheck = ModelCheckpoint('model/'+time.strftime(f'%Y-%m-%d-%a-%H-%M-%S',time.localtime(time.time()))+'.h5',monitor='val_acc',save_best_only=True,mode='max')  \n",
    "    \n",
    "    callable = [modelcheck]  \n",
    "    train_set,val_set = get_train_val()\n",
    "    train_numb = len(train_set)  \n",
    "    valid_numb = len(val_set)  \n",
    "    print (\"the number of train data is\",train_numb,train_numb//BS)  \n",
    "    print (\"the number of val data is\",valid_numb,valid_numb//BS)\n",
    "    H = model.fit_generator(generator=generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,verbose=1,  \n",
    "                    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS,callbacks=callable,max_q_size=1)  \n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on SegNet Satellite Seg\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"plot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_parse():\n",
    "    # construct the argument parse and parse the arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-a\", \"--augment\",help=\"using data augment or not\",\n",
    "                    action=\"store_true\", default=False)\n",
    "    ap.add_argument(\"-m\", \"--model\", required=True,default='model/'+time.strftime(f'%Y-%m-%d %a %H:%M:%S',time.localtime(time.time()))+'.h5'\n",
    "                    ,help=\"path to output model\")\n",
    "    ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "                    help=\"path to output accuracy/loss plot\")\n",
    "    args = vars(ap.parse_args()) \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train()  \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
