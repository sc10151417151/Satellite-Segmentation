{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np \n",
    "from keras import *\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from Models.utils import MaxUnpooling2D,MaxPoolingWithArgmax2D\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering('th')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import gdal\n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "  \n",
    "#data_shape = 360*480  \n",
    "img_w = 256  \n",
    "img_h = 256  \n",
    "#有一个为背景  \n",
    "n_label =2\n",
    "  \n",
    "classes = [0. ,  1]  \n",
    "  \n",
    "labelencoder = LabelEncoder()  \n",
    "labelencoder.fit(classes)  \n",
    "\n",
    "\n",
    "\n",
    "def load_img(path, grayscale=False):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "        img = np.array(img,dtype=\"float\") / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def get_train_val(val_rate = 0.25):\n",
    "    train_url = []    \n",
    "    train_set = []\n",
    "    val_set  = []\n",
    "    filepath ='..\\..\\Python\\seg-data\\data_MB/test/'  \n",
    "    for pic in os.listdir(filepath + 'src'):\n",
    "        train_url.append(pic)\n",
    "    random.shuffle(train_url)\n",
    "    total_num = len(train_url)\n",
    "    val_num = int(val_rate * total_num)\n",
    "    for i in range(len(train_url)):\n",
    "        if i < val_num:\n",
    "            val_set.append(train_url[i]) \n",
    "        else:\n",
    "            train_set.append(train_url[i])\n",
    "    return train_set,val_set\n",
    "# data for training  \n",
    "\n",
    "\n",
    "\n",
    "# data for training  \n",
    "def generateData(batch_size,data=[]): \n",
    "    print ('generateData...')\n",
    "    filepath ='..\\..\\Python\\seg-data\\data_MB/test/'  \n",
    "    while True:  \n",
    "        train_data = []  \n",
    "        train_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))): \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            img = np.load((filepath + 'src/' + url))\n",
    "            #img = np.load( filepath + 'src/' + url ) \n",
    "            train_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,-1))  \n",
    " \n",
    "            train_label.append(label)  \n",
    "            if batch % batch_size==0: \n",
    "        \n",
    "                train_data = np.array(train_data)  \n",
    "                \n",
    "                train_label = np.array(train_label).flatten()  \n",
    "                train_label = labelencoder.transform(train_label)  \n",
    "                train_label = to_categorical(train_label, num_classes=n_label)  \n",
    "                train_label = train_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (train_data,train_label)  \n",
    "                train_data = []  \n",
    "                train_label = []  \n",
    "                batch = 0  \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data for validation \n",
    "def generateValidData(batch_size,data=[]):  \n",
    "    print ('generateValidData...')\n",
    "    filepath ='..\\..\\Python\\seg-data\\data_MB/test/'  \n",
    "    while True:  \n",
    "        valid_data = []  \n",
    "        valid_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))):  \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            img = np.load((filepath + 'src/' + url))\n",
    "            #img = np.load( filepath + 'src/' + url ) \n",
    "            valid_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,-1))  \n",
    " \n",
    "            valid_label.append(label) \n",
    "            if batch % batch_size==0:  \n",
    "                valid_data = np.array(valid_data)  \n",
    "                valid_label = np.array(valid_label).flatten()  \n",
    "                valid_label = labelencoder.transform(valid_label)  \n",
    "                valid_label = to_categorical(valid_label, num_classes=n_label)  \n",
    "                valid_label = valid_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (valid_data,valid_label)  \n",
    "                valid_data = []  \n",
    "                valid_label = []  \n",
    "                batch = 0  \n",
    "\n",
    "\n",
    "\n",
    "def SegNet():  \n",
    "    #assert input_height % 32 == 0\n",
    "    #assert input_width % 32 == 0\n",
    "    nClasses=2\n",
    "    input_height=256\n",
    "    input_width=256\n",
    "    img_input = Input(shape=( 4,input_height, input_width))\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x, mask_1 = MaxPoolingWithArgmax2D(name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x , mask_2 = MaxPoolingWithArgmax2D(name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x, mask_3 = MaxPoolingWithArgmax2D(name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "\n",
    "    x, mask_4 = MaxPoolingWithArgmax2D(name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x, mask_5 = MaxPoolingWithArgmax2D(name='block5_pool')(x)\n",
    "\n",
    "    Vgg_streamlined=Model(inputs=img_input,outputs=x)\n",
    "\n",
    "    # 加载vgg16的预训练权重\n",
    "    #Vgg_streamlined.load_weights(r\"E:\\Code\\PycharmProjects\\keras-segmentation\\data\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "    # 解码层\n",
    "    unpool_1 = MaxUnpooling2D()([x, mask_5])\n",
    "    y = Conv2D(512, (3,3), padding=\"same\")(unpool_1)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    unpool_2 = MaxUnpooling2D()([y, mask_4])\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(unpool_2)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    unpool_3 = MaxUnpooling2D()([y, mask_3])\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(unpool_3)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    unpool_4 = MaxUnpooling2D()([y, mask_2])\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\")(unpool_4)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = Conv2D(64, (3, 3), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    unpool_5 = MaxUnpooling2D()([y, mask_1])\n",
    "    y = Conv2D(64, (3, 3), padding=\"same\")(unpool_5)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    y = Conv2D(nClasses, (1, 1), padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    y = Reshape((-1, nClasses))(y)\n",
    "    y = Activation(\"softmax\")(y)\n",
    "\n",
    "    model=Model(inputs=img_input,outputs=y)\n",
    "    return model  \n",
    "\n",
    "\n",
    "def train(): \n",
    "    EPOCHS = 1000\n",
    "    BS = 4\n",
    "    model = SegNet() \n",
    "    \n",
    "    modelcheck = ModelCheckpoint('..\\..\\Python\\seg-data/model/4Bands-'+time.strftime(f'%Y-%m-%d-%a-%H-%M-%S',time.localtime(time.time()))+'.h5',monitor='val_acc',save_best_only=True,mode='max')  \n",
    "    \n",
    "    callable = [modelcheck]  \n",
    "    train_set,val_set = get_train_val()\n",
    "    train_numb = len(train_set)  \n",
    "    valid_numb = len(val_set)  \n",
    "    print (\"the number of train data is\",train_numb,train_numb//BS)  \n",
    "    print (\"the number of val data is\",valid_numb,valid_numb//BS)\n",
    "    H = model.fit_generator(generator=generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,verbose=1,  \n",
    "                    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS,callbacks=callable,max_q_size=1)  \n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on SegNet Satellite Seg\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"plot.png\")\n",
    "\n",
    "\n",
    "\n",
    "def args_parse():\n",
    "    # construct the argument parse and parse the arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-a\", \"--augment\",help=\"using data augment or not\",\n",
    "                    action=\"store_true\", default=False)\n",
    "    ap.add_argument(\"-m\", \"--model\", required=True,default='model/'+time.strftime(f'%Y-%m-%d %a %H:%M:%S',time.localtime(time.time()))+'.h5'\n",
    "                    ,help=\"path to output model\")\n",
    "    ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "                    help=\"path to output accuracy/loss plot\")\n",
    "    args = vars(ap.parse_args()) \n",
    "    return args\n",
    "\n",
    "m = SegNet()\n",
    "from keras.utils import plot_model\n",
    "plot_model(m, show_shapes=True, to_file='model_segnet.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
