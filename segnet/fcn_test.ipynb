{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_size(factor):\n",
    "    #\n",
    "    return 2*factor-factor%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_filt(size):\n",
    "    #\n",
    "    factor=(size+1)//2\n",
    "    if size %2==1:\n",
    "        center=factor-1\n",
    "    else:\n",
    "        center=factor-0.5\n",
    "    og=np.ogrid[:size,:size]\n",
    "    return(1-abs(og[0]-center)/factor)*\\\n",
    "          (1-abs(og[1]-center)/factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_upsample_weights(factor,number_of_classes):\n",
    "    filter_size=get_kernel_size(factor)\n",
    "    weights=np.zeros((filter_size,\n",
    "                    filter_size,\n",
    "                    number_of_classes,\n",
    "                    number_of_classes),dtype=np.float32)\n",
    "    upsample_kernel=upsample_filt(filter_size)\n",
    "    for i in range(number_of_classes):\n",
    "        #!!!!!\n",
    "        weights[:,:,i,i]=upsample_kernel\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-5476556b5581>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-108>\", line 2, in matplotlib\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"c:\\users\\shenchao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "slim=tf.contrib.slim\n",
    "sys.path.append(os.path.expanduser(\"../../week8/models-r1.5/research/slim/\"))\n",
    "from nets import vgg\n",
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"00000000:01:00.0\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#%env CUDA_DEVICE_ORDER=00000000:01:00.0\n",
    "#%env CUDA_VISIBLE_DEVICES=0\n",
    "checkpoints_dir=os.path.expanduser('data/pre_trained/')\n",
    "image_filename='object_2.jpg'\n",
    "annotation_filename='segment_2.png'\n",
    "fig_size=[15,4]\n",
    "plt.rcParams[\"figure.figsize\"]=fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "image_filename_placeholder=tf.placeholder(tf.string)\n",
    "annotation_filename_placeholder=tf.placeholder(tf.string)\n",
    "is_training_placeholder=tf.placeholder(tf.bool)\n",
    "feed_dict_to_use={image_filename_placeholder:image_filename,\n",
    "                 annotation_filename_placeholder:annotation_filename,\n",
    "                 is_training_placeholder:True}\n",
    "image_tensor=tf.read_file(image_filename_placeholder)\n",
    "annotation_tensor=tf.read_file(annotation_filename_placeholder)\n",
    "\n",
    "image_tensor=tf.image.decode_jpeg(image_tensor,channels=3)\n",
    "annotation_tensor=tf.image.decode_png(annotation_tensor,channels=1)\n",
    "\n",
    "class_labels_tensor=tf.greater_equal(annotation_tensor,1)\n",
    "background_labels_tensor=tf.less(annotation_tensor,1)\n",
    "\n",
    "bit_mask_class=tf.to_float(class_labels_tensor)\n",
    "bit_mask_background=tf.to_float(background_labels_tensor)\n",
    "\n",
    "combined_mask=tf.concat(axis=2,values=[bit_mask_background,\n",
    "                                      bit_mask_class,])\n",
    "tensor=combined_mask\n",
    "flat_labels=tf.reshape(tensor=combined_mask,shape=[-1,2])\n",
    "#!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-3ba9831457c7>:58: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.vgg_preprocessing import (_mean_image_subtraction,\n",
    "                                            _R_MEAN,_G_MEAN,_B_MEAN)\n",
    "upsample_factor=32\n",
    "number_of_classes=2\n",
    "log_folder=os.path.expanduser('segment_log_folder')\n",
    "vgg_checkpoint_path=os.path.join(checkpoints_dir,'vgg_16.ckpt')\n",
    "\n",
    "image_float=tf.to_float(image_tensor,name='ToFloat')\n",
    "original_shape=tf.shape(image_float)[0:2]\n",
    "\n",
    "mean_centered_image=_mean_image_subtraction(image_float,\n",
    "                                           [_R_MEAN,_G_MEAN,_B_MEAN])\n",
    "target_input_size_factor=tf.ceil(tf.div(tf.to_float(original_shape),\n",
    "                                       tf.to_float(upsample_factor)))\n",
    "target_input_size=tf.to_int32(tf.multiply(target_input_size_factor,upsample_factor))\n",
    "padding_size=(target_input_size-original_shape)//2\n",
    "\n",
    "mean_centered_image=tf.image.pad_to_bounding_box(mean_centered_image,\n",
    "                                                padding_size[0],\n",
    "                                                padding_size[1],\n",
    "                                                target_input_size[0],\n",
    "                                                target_input_size[1])\n",
    "\n",
    "processed_images=tf.expand_dims(mean_centered_image,0)\n",
    "\n",
    "upsample_filter_np=bilinear_upsample_weights(upsample_factor,\n",
    "                                             number_of_classes)\n",
    "\n",
    "upsample_filter_tensor=tf.Variable(upsample_filter_np,name='vgg_16/fc8/t_conv')\n",
    "\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    logits,end_points=vgg.vgg_16(processed_images,\n",
    "                                 num_classes=2,\n",
    "                              \n",
    "                                 is_training=is_training_placeholder,\n",
    "                              \n",
    "                                 spatial_squeeze=False,\n",
    "                              \n",
    "                                 fc_conv_padding='SAME')\n",
    "\n",
    "downsampled_logits_shape=tf.shape(logits)\n",
    "\n",
    "upsampled_logits_shape=tf.stack([downsampled_logits_shape[0],\n",
    "                                 original_shape[0],\n",
    "                                 original_shape[1],\n",
    "                                 downsampled_logits_shape[3]\n",
    "                                 ])\n",
    "upsampled_logits=tf.nn.conv2d_transpose(logits,upsample_filter_tensor,\n",
    "                                        output_shape=upsampled_logits_shape,\n",
    "                                        strides=[1,upsample_factor,upsample_factor,1],\n",
    "                                        padding='SAME'\n",
    "                                       )\n",
    "\n",
    "\n",
    "flat_logits=tf.reshape(tensor=upsampled_logits,shape=(-1,number_of_classes))\n",
    "\n",
    "cross_entropies=tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits,\n",
    "                                                       labels=flat_labels)\n",
    "\n",
    "cross_entropy_sum=tf.reduce_sum(cross_entropies)\n",
    "\n",
    "pred=tf.argmax(upsampled_logits,axis=3)\n",
    "\n",
    "probabilities=tf.nn.softmax(upsampled_logits)\n",
    "\n",
    "with tf.variable_scope(\"adam_vars\"):\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "    gradients=optimizer.compute_gradients(loss=cross_entropy_sum)\n",
    "    for grad_var_pair in gradients:\n",
    "        current_variable=grad_var_pair[1]\n",
    "        current_gradient=grad_var_pair[0]\n",
    "        gradient_name_to_save=current_variable.name.replace(\":\",\"_\")\n",
    "        tf.summary.histogram(gradient_name_to_save,current_gradient)\n",
    "    train_step=optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "vgg_except_fc8_weights=slim.get_variables_to_restore(exclude=['vgg_16/fc8','adam_vars'])\n",
    "vgg_fc8_weights=slim.get_variables_to_restore(include=['vgg_16/fc8'])\n",
    "adam_optimizer_variables=slim.get_variables_to_restore(include=['adam_vars'])\n",
    "tf.summary.scalar('cross_entropy_loss',cross_entropy_sum)\n",
    "merged_summary_op=tf.summary.merge_all()\n",
    "summary_string_writer=tf.summary.FileWriter(log_folder)\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "read_vgg_weights_except_fc8_func=slim.assign_from_checkpoint_fn(vgg_checkpoint_path,\n",
    "                                                                vgg_except_fc8_weights)\n",
    "\n",
    "vgg_fc8_weights_initializer=tf.variables_initializer(adam_optimizer_variables)\n",
    "\n",
    "optimization_variables_initializer=tf.variables_initializer(adam_optimizer_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_op=tf.global_variables_initializer()\n",
    "\n",
    "sess_config=tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth=True\n",
    "sess= tf.Session(config=sess_config)\n",
    "with sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    read_vgg_weights_except_fc8_func(sess)    \n",
    "    sess.run(vgg_fc8_weights_initializer)\n",
    "    sess.run(optimization_variables_initializer)\n",
    "\n",
    "    train_image,train_annotation=sess.run([image_tensor,annotation_tensor],\n",
    "                                         feed_dict=feed_dict_to_use)\n",
    "    f,(ax1,ax2)=plt.subplots(1,2,sharey=True)\n",
    "    ax1.imshow(train_image)\n",
    "    ax1.set_title(\"input image\")\n",
    "    probability_graph=ax2.imshow(np.dstack((train_annotation,)*3)*100)\n",
    "    ax2.set_title(\"input ground truth annotation\")\n",
    "    plt.show()\n",
    "    downsample_logits_value,train_annotation=sess.run([downsampled_logits_shape,annotation_tensor],feed_dict=feed_dict_to_use)\n",
    "    print(downsampled_logits_shape.shape)\n",
    "    \n",
    "    for i in range(30):\n",
    "        print(i)\n",
    "        loss,summary_string=sess.run([cross_entropy_sum,merged_summary_op],\n",
    "                                    feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        sess.run(train_step,feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        pred_np,probabilities_np=sess.run([pred,probabilities],\n",
    "                                         feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        summary_string_writer.add_summary(summary_string,i)\n",
    "        \n",
    "        #camp='seismic'                 \n",
    "        f,(ax1,ax2,ax3)=plt.subplots(1,3,sharey=True)\n",
    "        ax1.imshow(np.uint8(pred_np.squeeze()!=1),vmax=1.5,vmin=-0.4)\n",
    "        ax1.set_title('Arg max.interation #'+str(i))\n",
    "        probability_graph=ax2.imshow(probabilities_np.squeeze()[:,:,0])\n",
    "        ax2.set_title('probability of the class.Interation # '+str(i))\n",
    "        mask=np.multiply(np.uint32(pred_np.squeeze()),128)\n",
    "        mask=np.stack([mask,]*3,axis=-1)\n",
    "        masked_image=np.uint8(np.clip(train_image+mask,0,255))\n",
    "        probability_graph=ax3.imshow(masked_image)\n",
    "        plt.colorbar(probability_graph)\n",
    "        plt.show()\n",
    "        print(\"current loss:\"+str(loss))\n",
    "    feed_dict_to_use[is_training_placeholder]=False\n",
    "    final_predictions,final_probabilities,final_loss=sess.run([pred,\n",
    "                                                              probabilities,\n",
    "                                                              cross_entropy_sum],\n",
    "                                                             feed_dict=feed_dict_to_use)\n",
    "    f,(ax1,ax2,ax3)=plt.subplots(1,3,sharey=True)\n",
    "    ax1.imshow(np.uint8(final_predictions.squeeze()!=1),\n",
    "               vmax=1.5,\n",
    "               vmin=-0.4\n",
    "               )\n",
    "    ax1.set_title('final argmax')\n",
    "    probability_graph=ax2.imshow(final_probabilities.squeeze()[:,:,0])\n",
    "    plt.colorbar(probability_graph)\n",
    "    mask=np.multiply(np.uint32(final_predictions.squeeze()),128)\n",
    "    mask=np.stack([np.zeros(mask.shape),\n",
    "               mask,\n",
    "               np.zeros(mask.shape)],axis=-1)\n",
    "    masked_image=np.uint(np.clip(train_image+mask,0,255))\n",
    "    probability_graph=ax3.imshow(masked_image)\n",
    "    plt.show()\n",
    "    print(\"fina loss:\",str(final_loss))\n",
    "summary_string_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 762\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f1ae519eb7cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprocessed_probabilities\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_probabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessed_probabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_image' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#path = \"/home/dpakhom1/dense_crf_python/\"\n",
    "#sys.path.append(path)\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "    create_pairwise_gaussian, softmax_to_unary\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "image = train_image\n",
    "processed_probabilities=final_probabilities.squeeze()\n",
    "softmax = processed_probabilities.transpose((2, 0, 1))\n",
    "\n",
    "# 输入数据应为概率值的负对数\n",
    "# 你可以在softmax_to_unary函数的定义中找到更多信息\n",
    "unary = softmax_to_unary(softmax)\n",
    "print(unary.shape)\n",
    "\n",
    "# 输入数据应为C-连续的——我们使用了Cython封装器\n",
    "unary = np.ascontiguousarray(unary)\n",
    "\n",
    "d = dcrf.DenseCRF(image.shape[0] * image.shape[1], 2)\n",
    "\n",
    "d.setUnaryEnergy(unary)\n",
    "\n",
    "# 潜在地对空间上相邻的小块分割区域进行惩罚——促使产生更多空间连续的分割区域\n",
    "feats = create_pairwise_gaussian(sdims=(10, 10), shape=image.shape[:2])\n",
    "\n",
    "d.addPairwiseEnergy(feats, compat=3,\n",
    "                    kernel=dcrf.DIAG_KERNEL,\n",
    "                    normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "# 这将创建与颜色相关的图像特征——因为我们从卷积神经网络中得到的分割结果非常粗糙，\n",
    "# 我们可以使用局部的颜色特征来改善分割结果\n",
    "feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n",
    "                                   img=image, chdim=2)\n",
    "\n",
    "d.addPairwiseEnergy(feats, compat=10,\n",
    "                     kernel=dcrf.DIAG_KERNEL,\n",
    "                     normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "Q = d.inference(5)\n",
    "\n",
    "res = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
    "\n",
    "#cmap = plt.get_cmap('bwr')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.imshow(res, vmax=1.5, vmin=-0.4)\n",
    "ax1.set_title('Segmentation with CRF post-processing')\n",
    "probability_graph = ax2.imshow(np.dstack((train_annotation,)*3)*100)\n",
    "ax2.set_title('Ground-Truth Annotation')\n",
    "mask=np.multiply(np.uint32(res.squeeze()),128)\n",
    "mask=np.stack([np.zeros(mask.shape),\n",
    "              mask,\n",
    "              np.zeros(mask.shape)],axis=-1)\n",
    "masked_image=np.uint8(np.clip(np.uint32(train_image)+mask,0,255))\n",
    "probability_graph=ax3.imshow(masked_image)\n",
    "\n",
    "plt.show()\n",
    "intersection=np.logical_and(res,train_annotation.squeeze())\n",
    "union=np.logical_or(res,train_annotation.squeeze())\n",
    "sum_intersection=np.sum(intersection)\n",
    "sum_union=np.sum(union)\n",
    "print('IoU:%.2f%%'%((sum_intersection/sum_union)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "image_sets = ['test.tif']\n",
    "data_tif=gdal.Open('./data_MB/' + image_sets[0])\n",
    "x_width  = data_tif.RasterXSize    #栅格矩阵的列数\n",
    "x_height = data_tif.RasterYSize\n",
    "data=data_tif.ReadAsArray(0,0,x_width,x_height)\n",
    "im_data=np.append(np.append(np.append(data[3,:,:][:,:,np.newaxis],data[2,:,:][:,:,np.newaxis],axis=2),data[1,:,:][:,:,np.newaxis],axis=2),data[0,:,:][:,:,np.newaxis],axis=2)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1960, 2505)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 2505, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "label_img_gray = cv2.imread('./data_MB/test_label.png' ,cv2.IMREAD_GRAYSCALE)  \n",
    "label= cv2.imread('./data_MB/test_label.png' )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 2505)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_img_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 2505, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
