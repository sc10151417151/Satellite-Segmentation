{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization,Reshape,Permute,Activation  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering('th')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import gdal\n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "  \n",
    "#data_shape = 360*480  \n",
    "img_w = 256  \n",
    "img_h = 256  \n",
    "#有一个为背景  \n",
    "n_label =2\n",
    "  \n",
    "classes = [0. ,  1]  \n",
    "  \n",
    "labelencoder = LabelEncoder()  \n",
    "labelencoder.fit(classes)  \n",
    "\n",
    "image_sets = ['1.png','2.png','3.png']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, grayscale=False):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "        img = np.array(img,dtype=\"float\") / 255.0\n",
    "    return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='./data_MB/test/'  \n",
    "\n",
    "def get_train_val(val_rate = 0.25):\n",
    "    train_url = []    \n",
    "    train_set = []\n",
    "    val_set  = []\n",
    "    for pic in os.listdir(filepath + 'src'):\n",
    "        train_url.append(pic)\n",
    "    random.shuffle(train_url)\n",
    "    total_num = len(train_url)\n",
    "    val_num = int(val_rate * total_num)\n",
    "    for i in range(len(train_url)):\n",
    "        if i < val_num:\n",
    "            val_set.append(train_url[i]) \n",
    "        else:\n",
    "            train_set.append(train_url[i])\n",
    "    return train_set,val_set\n",
    "\n",
    "# data for training  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for training  \n",
    "def generateData(batch_size,data=[]):  \n",
    "    #print 'generateData...'\n",
    "    while True:  \n",
    "        train_data = []  \n",
    "        train_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))): \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            dataset=gdal.Open(\"data_MB/test.tif\")\n",
    "            #img = load_img(filepath + 'src/' + url\n",
    "            im_width = dataset.RasterXSize    #栅格矩阵的列数\n",
    "            im_height = dataset.RasterYSize\n",
    "            img = dataset.ReadAsArray(0,0,im_width,im_height)[:,0:256,0:256]\n",
    "            #img = np.load( filepath + 'src/' + url ) \n",
    "            train_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,-1))  \n",
    "            \n",
    "            # print label.shape  \n",
    "            train_label.append(label)  \n",
    "            if batch % batch_size==0: \n",
    "                #print 'get enough bacth!\\n'\n",
    "                train_data = np.array(train_data)  \n",
    "                train_label = np.array(train_label).flatten()  \n",
    "                train_label = labelencoder.transform(train_label)  \n",
    "                train_label = to_categorical(train_label, num_classes=n_label)  \n",
    "                train_label = train_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (train_data,train_label)  \n",
    "                train_data = []  \n",
    "                train_label = []  \n",
    "                batch = 0  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data for validation \n",
    "def generateValidData(batch_size,data=[]):  \n",
    "    #print 'generateValidData...'\n",
    "    while True:  \n",
    "        valid_data = []  \n",
    "        valid_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))):  \n",
    "            url = data[i]\n",
    "            batch += 1  \n",
    "            dataset=gdal.Open(\"data_MB/test.tif\")\n",
    "            #img = load_img(filepath + 'src/' + url\n",
    "            im_width = dataset.RasterXSize    #栅格矩阵的列数\n",
    "            im_height = dataset.RasterYSize\n",
    "            img = dataset.ReadAsArray(0,0,im_width,im_height)[:,0:256,0:256]\n",
    "            valid_data.append(img)  \n",
    "            label = load_img((filepath + 'label/' + url).replace('npy','png'), grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,))  \n",
    "            # print label.shape  \n",
    "            valid_label.append(label)  \n",
    "            if batch % batch_size==0:  \n",
    "                valid_data = np.array(valid_data)  \n",
    "                valid_label = np.array(valid_label).flatten()  \n",
    "                valid_label = labelencoder.transform(valid_label)  \n",
    "                valid_label = to_categorical(valid_label, num_classes=n_label)  \n",
    "                valid_label = valid_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (valid_data,valid_label)  \n",
    "                valid_data = []  \n",
    "                valid_label = []  \n",
    "                batch = 0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def SegNet():  \n",
    "    model = Sequential()  \n",
    "    #encoder  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(4,img_w,img_h),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(8,8)  \n",
    "    #decoder  \n",
    "    model.add(UpSampling2D(size=(2,2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(256,256)  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(4,img_w, img_h), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(n_label, (1, 1), strides=(1, 1), padding='same'))  \n",
    "    model.add(Reshape((n_label,img_w*img_h)))  \n",
    "    #axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)  \n",
    "    model.add(Permute((2,1)))  \n",
    "    model.add(Activation('softmax'))  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  \n",
    "    model.summary()  \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(): \n",
    "    EPOCHS = 1\n",
    "    BS = 4\n",
    "    model = SegNet() \n",
    "    \n",
    "    modelcheck = ModelCheckpoint('model/'+time.strftime(f'%Y-%m-%d-%a-%H-%M-%S',time.localtime(time.time()))+'.h5',monitor='val_acc',save_best_only=True,mode='max')  \n",
    "    \n",
    "    callable = [modelcheck]  \n",
    "    train_set,val_set = get_train_val()\n",
    "    train_numb = len(train_set)  \n",
    "    valid_numb = len(val_set)  \n",
    "    print (\"the number of train data is\",train_numb)  \n",
    "    print (\"the number of val data is\",valid_numb)\n",
    "    H = model.fit_generator(generator=generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,verbose=1,  \n",
    "                    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS,callbacks=callable,max_q_size=1)  \n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on SegNet Satellite Seg\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"plot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_parse():\n",
    "    # construct the argument parse and parse the arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-a\", \"--augment\",help=\"using data augment or not\",\n",
    "                    action=\"store_true\", default=False)\n",
    "    ap.add_argument(\"-m\", \"--model\", required=True,default='model/'+time.strftime(f'%Y-%m-%d %a %H:%M:%S',time.localtime(time.time()))+'.h5'\n",
    "                    ,help=\"path to output model\")\n",
    "    ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "                    help=\"path to output accuracy/loss plot\")\n",
    "    args = vars(ap.parse_args()) \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 256, 256)      2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 256, 256)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 64, 64)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 64, 64)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 256, 64, 64)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 32, 32)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 512, 32, 32)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 512, 32, 32)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 512, 16, 16)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 512, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 512, 32, 32)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 512, 32, 32)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 512, 32, 32)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 512, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 256, 64, 64)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 256, 64, 64)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 256, 64, 64)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 256, 64, 64)       256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 256, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 128)     295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 128, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 256, 256)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 256, 256)      36928     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 2, 256, 256)       130       \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2, 65536)          0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 65536, 2)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 65536, 2)          0         \n",
      "=================================================================\n",
      "Total params: 31,796,482\n",
      "Trainable params: 31,792,066\n",
      "Non-trainable params: 4,416\n",
      "_________________________________________________________________\n",
      "the number of train data is 75\n",
      "the number of val data is 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chao\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., steps_per_epoch=18, epochs=1, verbose=1, validation_data=<generator..., validation_steps=6, callbacks=[<keras.ca..., max_queue_size=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "18/18 [==============================] - ETA: 1:23 - loss: 0.6931 - acc: 0.669 - ETA: 41s - loss: 0.6923 - acc: 0.826 - ETA: 27s - loss: 0.6904 - acc: 0.88 - ETA: 20s - loss: 0.6887 - acc: 0.89 - ETA: 16s - loss: 0.6869 - acc: 0.90 - ETA: 13s - loss: 0.6846 - acc: 0.91 - ETA: 10s - loss: 0.6842 - acc: 0.89 - ETA: 8s - loss: 0.6822 - acc: 0.9012 - ETA: 7s - loss: 0.6808 - acc: 0.899 - ETA: 6s - loss: 0.6792 - acc: 0.900 - ETA: 5s - loss: 0.6778 - acc: 0.898 - ETA: 4s - loss: 0.6756 - acc: 0.906 - ETA: 3s - loss: 0.6733 - acc: 0.914 - ETA: 2s - loss: 0.6724 - acc: 0.908 - ETA: 1s - loss: 0.6706 - acc: 0.910 - ETA: 1s - loss: 0.6685 - acc: 0.915 - ETA: 0s - loss: 0.6688 - acc: 0.900 - 11s 638ms/step - loss: 0.6672 - acc: 0.9017 - val_loss: 0.6409 - val_acc: 0.8930\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train()  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
